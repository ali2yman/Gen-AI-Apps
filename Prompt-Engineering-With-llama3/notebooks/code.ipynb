{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb3cde7",
   "metadata": {},
   "source": [
    "<B>Load the llama3 token from .env</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11eed9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface-cli login   >>> we can use this onetime in the terminal \n",
    "\n",
    "# or throw this \n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "# api_token = os.getenv(\"LLAMA_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75243d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Check the GPU availability    \n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366cf82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5deee77edaf4e4dae5d72f81375c351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "def initialize_llama3(model_id=\"meta-llama/Llama-3.2-3B-Instruct\", use_4bit=True):\n",
    "    \"\"\"\n",
    "    Initialize LLaMA 3 model from Hugging Face using Transformers.\n",
    "    \n",
    "    Args:\n",
    "        model_id (str): Hugging Face model ID \n",
    "        use_4bit (bool): Whether to load the model using 4-bit quantization for memory efficiency\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, tokenizer, text-generation pipeline)\n",
    "    \"\"\"\n",
    "    print(f\"Loading model: {model_id}\")\n",
    "\n",
    "    # Load the tokenizer (no need to manually pass token)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    # Load the model\n",
    "    if use_4bit:\n",
    "        # Optional: requires `bitsandbytes` installed\n",
    "        quantization_config = {\n",
    "            \"load_in_4bit\": True,\n",
    "            \"bnb_4bit_compute_dtype\": torch.bfloat16,\n",
    "            \"bnb_4bit_quant_type\": \"nf4\",\n",
    "            \"bnb_4bit_use_double_quant\": True,\n",
    "        }\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            quantization_config=quantization_config,\n",
    "        )\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.bfloat16\n",
    "        )\n",
    "\n",
    "    # Create a text-generation pipeline\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        return_full_text=False\n",
    "    )\n",
    "\n",
    "    return model, tokenizer, pipe\n",
    "\n",
    "# Example usage\n",
    "model, tokenizer, llama3_pipe = initialize_llama3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1dd502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(prompt, max_new_tokens=500, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Send a prompt to LLaMA 3 and get a response.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the model\n",
    "        max_new_tokens (int): Maximum length of the response\n",
    "        temperature (float): Controls randomness (0-1)\n",
    "\n",
    "    Returns:\n",
    "        str: The model's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Format the prompt using LLaMA 3's chat template\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "        # Generate the response\n",
    "        result = llama3_pipe(\n",
    "            formatted_prompt,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "\n",
    "        return result[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLaMA 3: {e}\")\n",
    "        return None\n",
    "def calculate_response_metrics(response):\n",
    "    \"\"\"\n",
    "    Calculate basic metrics about the response.\n",
    "\n",
    "    Args:\n",
    "        response (str): The model's response\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of metrics\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"word_count\": len(response.split()),\n",
    "        \"char_count\": len(response),\n",
    "        \"sentence_count\": response.count('. ') + response.count('! ') + response.count('? ')\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf0ebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLaMA 3 Response:\n",
      "assistant\n",
      "\n",
      "Prompt engineering is a subfield of natural language processing (NLP) that focuses on designing and optimizing the input prompts used to elicit specific responses from language models, such as chatbots, virtual assistants, and other AI systems. The goal of prompt engineering is to craft high-quality prompts that elicit the desired output from the model, taking into account its strengths, weaknesses, and limitations.\n",
      "\n",
      "Prompt engineering involves several key aspects:\n",
      "\n",
      "1. **Prompt design**: Creating well-structured and clear prompts that accurately convey the desired intent, context, and requirements.\n",
      "2. **Prompt optimization**: Refining the prompt to achieve the desired outcome, such as improving response accuracy, relevance, and coherence.\n",
      "3. **Prompt tuning**: Adjusting the prompt to accommodate the model's limitations, biases, and idiosyncrasies.\n",
      "4. **Prompt evaluation**: Assessing the effectiveness of the prompt in eliciting the desired response, and making adjustments as needed.\n",
      "\n",
      "Effective prompt engineering requires a deep understanding of the language model's capabilities, limitations, and behavior. It involves using various techniques, such as:\n",
      "\n",
      "1. **Prompt templates**: Using pre-defined templates to structure the prompt and guide the model's response.\n",
      "2. **Entity recognition**: Identifying and incorporating specific entities, such as names, dates, and locations, to provide context and relevance.\n",
      "3. **Contextualization**: Providing relevant context and background information to help the model understand the situation and generate a more accurate response.\n",
      "4. **Feedback mechanisms**: Using feedback mechanisms, such as user input or evaluation metrics, to refine the prompt and improve the model's performance over time.\n",
      "\n",
      "By applying prompt engineering techniques, developers can:\n",
      "\n",
      "1. **Improve response accuracy**: Craft high-quality prompts that elicit accurate and relevant responses from language models.\n",
      "2. **Increase efficiency**: Optimize prompts to reduce the number of prompts required to achieve the desired outcome.\n",
      "3. **Enhance user experience**: Create more effective and engaging interactions with users, leading to improved satisfaction and loyalty.\n",
      "\n",
      "In summary, prompt engineering is a crucial aspect of NLP that involves designing, optimizing, and refining prompts to elicit specific responses from language models, ultimately leading to improved performance, efficiency, and user experience.\n"
     ]
    }
   ],
   "source": [
    "# Test the LLaMA 3 setup\n",
    "test_prompt = \"What is prompt engineering?\"\n",
    "response = query_llm(test_prompt)\n",
    "\n",
    "# Print the model's response\n",
    "print(\"LLaMA 3 Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f410d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a set of tasks for comparison\n",
    "tasks = [\n",
    "    \"Classify the following review as positive or negative: 'The service was terrible but the food was amazing.'\",\n",
    "    \"Identify the emotion in this sentence: 'I can't believe I failed the exam after studying so hard.'\",\n",
    "    \"Categorize this news headline as politics, sports, or entertainment: 'New trade agreement signed between countries.'\",\n",
    "    \"Determine if this statement is a fact or opinion: 'Coffee is the best beverage for morning productivity.'\"\n",
    "]\n",
    "few_shot_examples = {\n",
    "    \"sentiment\": [\n",
    "        {\"example\": \"The movie was fantastic and I enjoyed every minute.\", \"label\": \"Positive\"},\n",
    "        {\"example\": \"The hotel room was dirty and the staff was rude.\", \"label\": \"Negative\"},\n",
    "        {\"example\": \"While the price was high, the quality was worth it.\", \"label\": \"Positive\"}\n",
    "    ],\n",
    "    \"emotion\": [\n",
    "        {\"example\": \"I just won the lottery!\", \"label\": \"Joy\"},\n",
    "        {\"example\": \"My dog passed away yesterday.\", \"label\": \"Sadness\"},\n",
    "        {\"example\": \"They didn't invite me to the party.\", \"label\": \"Disappointment\"}\n",
    "    ],\n",
    "    \"categorization\": [\n",
    "        {\"example\": \"Local election results surprise analysts.\", \"label\": \"Politics\"},\n",
    "        {\"example\": \"New movie breaks box office records.\", \"label\": \"Entertainment\"},\n",
    "        {\"example\": \"Team wins championship for the third time.\", \"label\": \"Sports\"}\n",
    "    ],\n",
    "    \"fact_opinion\": [\n",
    "        {\"example\": \"The Earth orbits around the Sun.\", \"label\": \"Fact\"},\n",
    "        {\"example\": \"Summer is the best season of the year.\", \"label\": \"Opinion\"},\n",
    "        {\"example\": \"Chocolate contains caffeine.\", \"label\": \"Fact\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b7f852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Classify the following review as positive or negative: 'The service was terrible but the food was amazing.'\n",
      "Response: assistant\n",
      "\n",
      "This review is mixed, but leaning towards being positive. Although the reviewer mentions that the \"service was terrible\", they also state that the \"food was amazing\", which suggests that the positive aspect of their experience outweighed the negative one.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Identify the emotion in this sentence: 'I can't believe I failed the exam after studying so hard.'\n",
      "Response: assistant\n",
      "\n",
      "The emotion expressed in the sentence is disappointment.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Categorize this news headline as politics, sports, or entertainment: 'New trade agreement signed between countries.'\n",
      "Response: assistant\n",
      "\n",
      "This news headline can be categorized as 'politics'.\n",
      "\n",
      "Task: Determine if this statement is a fact or opinion: 'Coffee is the best beverage for morning productivity.'\n",
      "Response: assistant\n",
      "\n",
      "This statement is an opinion. The reason is that \"best\" is a subjective term, and people may have different preferences when it comes to their morning beverage. While some people may agree that coffee is the best beverage for morning productivity, others may prefer tea, juice, or other options.\n",
      "\n",
      "Additionally, the statement is not supported by objective evidence, and there is no scientific proof that coffee is the only or even the best beverage for morning productivity. It's a matter of personal taste and individual experiences.\n",
      "\n",
      "Therefore, it's an opinion, not a fact.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def zero_shot_prompt(task):\n",
    "    \"\"\"\n",
    "    Perform zero-shot prompting for a given task.\n",
    "\n",
    "    Args:\n",
    "        task (str): The task to perform\n",
    "\n",
    "    Returns:\n",
    "        str: The model's response\n",
    "    \"\"\"\n",
    "    prompt = task\n",
    "    return query_llm(prompt)\n",
    "# Initialize results list\n",
    "zero_shot_results = []\n",
    "\n",
    "# Loop over all tasks and collect results\n",
    "for task in tasks:\n",
    "    response = zero_shot_prompt(task)\n",
    "    zero_shot_results.append({\n",
    "        \"task\": task,\n",
    "        \"response\": response,\n",
    "        \"metrics\": calculate_response_metrics(response)\n",
    "    })\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"Task: {task}\")\n",
    "    print(f\"Response: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c1baf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Classify the following review as positive or negative: 'The service was terrible but the food was amazing.'\n",
      "Examples used: sentiment\n",
      "Response: assistant\n",
      "\n",
      "Negative\n",
      "\n",
      "Explanation: Although the service was terrible, the positive aspect (the food) outweighs the negative, so the overall sentiment is still considered positive.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Identify the emotion in this sentence: 'I can't believe I failed the exam after studying so hard.'\n",
      "Examples used: emotion\n",
      "Response: assistant\n",
      "\n",
      "Anger\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Categorize this news headline as politics, sports, or entertainment: 'New trade agreement signed between countries.'\n",
      "Examples used: categorization\n",
      "Response: assistant\n",
      "\n",
      "Politics\n",
      "\n",
      "Task: Determine if this statement is a fact or opinion: 'Coffee is the best beverage for morning productivity.'\n",
      "Examples used: fact_opinion\n",
      "Response: assistant\n",
      "\n",
      "Opinion\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def few_shot_prompt(task, examples):\n",
    "    \"\"\"\n",
    "    Perform few-shot prompting for a given task.\n",
    "\n",
    "    Args:\n",
    "        task (str): The task to perform\n",
    "        examples (list): List of example dictionaries with 'example' and 'label' keys\n",
    "\n",
    "    Returns:\n",
    "        str: The model's response\n",
    "    \"\"\"\n",
    "    # Construct the prompt with examples\n",
    "    prompt = \"Here are some examples:\\n\\n\"\n",
    "\n",
    "    for example in examples:\n",
    "        prompt += f\"Input: {example['example']}\\nOutput: {example['label']}\\n\\n\"\n",
    "\n",
    "    # Extract the actual input text from the task\n",
    "    if ': ' in task:\n",
    "        input_text = task.split(': ', 1)[1]\n",
    "    else:\n",
    "        input_text = task\n",
    "\n",
    "    prompt += f\"Input: {input_text}\\nOutput:\"\n",
    "    return query_llm(prompt)\n",
    "# Map each task index to its corresponding example category\n",
    "task_to_examples = {\n",
    "    0: \"sentiment\",\n",
    "    1: \"emotion\",\n",
    "    2: \"categorization\",\n",
    "    3: \"fact_opinion\"\n",
    "}\n",
    "# Store results\n",
    "few_shot_results = []\n",
    "\n",
    "for i, task in enumerate(tasks):\n",
    "    example_type = task_to_examples[i]\n",
    "    examples = few_shot_examples[example_type]\n",
    "\n",
    "    response = few_shot_prompt(task, examples)\n",
    "    few_shot_results.append({\n",
    "        \"task\": task,\n",
    "        \"response\": response,\n",
    "        \"metrics\": calculate_response_metrics(response),\n",
    "        \"example_type\": example_type\n",
    "    })\n",
    "\n",
    "    # Print output\n",
    "    print(f\"Task: {task}\")\n",
    "    print(f\"Examples used: {example_type}\")\n",
    "\n",
    "\n",
    "    print(f\"Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfcea90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Task  \\\n",
      "0  Classify the following review as positive or n...   \n",
      "1  Identify the emotion in this sentence: 'I can'...   \n",
      "2  Categorize this news headline as politics, spo...   \n",
      "3  Determine if this statement is a fact or opini...   \n",
      "\n",
      "                                  Zero-shot Response  \\\n",
      "0  assistant\\n\\nThis review is mixed, but leaning...   \n",
      "1  assistant\\n\\nThe emotion expressed in the sent...   \n",
      "2  assistant\\n\\nThis news headline can be categor...   \n",
      "3  assistant\\n\\nThis statement is an opinion. The...   \n",
      "\n",
      "                                   Few-shot Response  \n",
      "0  assistant\\n\\nNegative\\n\\nExplanation: Although...  \n",
      "1                                 assistant\\n\\nAnger  \n",
      "2                              assistant\\n\\nPolitics  \n",
      "3                               assistant\\n\\nOpinion  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Create a comparison dataframe\n",
    "comparison_data = []\n",
    "\n",
    "for i in range(len(tasks)):\n",
    "    comparison_data.append({\n",
    "        \"Task\": tasks[i],\n",
    "        \"Zero-shot Response\": zero_shot_results[i][\"response\"],\n",
    "        \"Few-shot Response\": few_shot_results[i][\"response\"]\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Display the comparison\n",
    "print(comparison_df)\n",
    "# Save the comparison to a CSV file\n",
    "comparison_df.to_csv(\"zero_shot_vs_few_shot_comparison.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5000eb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discounted price, what is the final price of the shirt?\n",
      "Response: assistant\n",
      "\n",
      "To find the final price of the shirt, we need to calculate the discount in two steps:\n",
      "\n",
      "1. Calculate the 25% discount from the original price:\n",
      "$100 * 0.25 = $25 (discount amount)\n",
      "$100 - $25 = $75 (discounted price)\n",
      "\n",
      "2. Calculate the additional 10% discount from the discounted price:\n",
      "$75 * 0.10 = $7.50 (discount amount)\n",
      "$75 - $7.50 = $67.50 (final price)\n",
      "\n",
      "The final price of the shirt is $67.50.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\n",
      "Response: assistant\n",
      "\n",
      "To find the distance the train will travel, you need to multiply its speed by the time it travels.\n",
      "\n",
      "Distance = Speed * Time\n",
      "Distance = 60 miles/hour * 2.5 hours\n",
      "Distance = 150 miles\n",
      "\n",
      "The train will travel 150 miles in 2.5 hours.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?\n",
      "Response: assistant\n",
      "\n",
      "To solve this problem, we can use the concept of proportionality. Since 5 machines can make 5 widgets in 5 minutes, we can set up a proportion to find out how long it would take 100 machines to make 100 widgets.\n",
      "\n",
      "Let's set up the proportion:\n",
      "\n",
      "5 machines / 5 minutes = 100 machines / x minutes\n",
      "\n",
      "We can cross-multiply to get:\n",
      "\n",
      "5x = 100 * 5\n",
      "\n",
      "Simplifying the equation, we get:\n",
      "\n",
      "5x = 500\n",
      "\n",
      "Dividing both sides by 5, we get:\n",
      "\n",
      "x = 100\n",
      "\n",
      "So, it would take 100 machines 100 minutes to make 100 widgets.\n",
      "\n",
      "Problem: A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\n",
      "Response: assistant\n",
      "\n",
      "To solve this problem, let's use the information given:\n",
      "\n",
      "1. The total cost of the bat and the ball is $1.10.\n",
      "2. The bat costs $1.00 more than the ball.\n",
      "\n",
      "Let's denote the cost of the ball as x. Since the bat costs $1.00 more than the ball, the cost of the bat is x + $1.00.\n",
      "\n",
      "The total cost of the bat and the ball is $1.10, so we can write the equation:\n",
      "\n",
      "x + (x + $1.00) = $1.10\n",
      "\n",
      "Combine like terms:\n",
      "\n",
      "2x + $1.00 = $1.10\n",
      "\n",
      "Subtract $1.00 from both sides:\n",
      "\n",
      "2x = $0.10\n",
      "\n",
      "Divide both sides by 2:\n",
      "\n",
      "x = $0.05\n",
      "\n",
      "So, the ball costs $0.05.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reasoning_problems = [\n",
    "    [\"If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discounted price, what is the final price of the shirt?\"],\n",
    "    [\"A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\"],\n",
    "    [\"If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?\"],\n",
    "    [\"A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\"]\n",
    "]\n",
    "\n",
    "def standard_prompt(problem):\n",
    "    \"\"\"\n",
    "    Perform standard prompting for a reasoning problem.\n",
    "\n",
    "    Args:\n",
    "        problem (str): The reasoning problem\n",
    "\n",
    "    Returns:\n",
    "        str: The model's response\n",
    "    \"\"\"\n",
    "    prompt = f\"Answer the following question: {problem}\"\n",
    "    return query_llm(prompt)\n",
    "\n",
    "# Test standard prompting on our reasoning problems\n",
    "standard_results = []\n",
    "for problem in reasoning_problems:\n",
    "    response = standard_prompt(problem[0])  # Get the response from the model\n",
    "    standard_results.append({\n",
    "        \"problem\": problem[0],\n",
    "        \"response\": response\n",
    "    })\n",
    "    print(f\"Problem: {problem[0]}\")\n",
    "    print(f\"Response: {response}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f627da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discounted price, what is the final price of the shirt?\n",
      "CoT Response: assistant\n",
      "\n",
      "To find the final price of the shirt, let's calculate step by step:\n",
      "\n",
      "1. The shirt is originally $100.\n",
      "2. The first discount is 25% off the original price.\n",
      "   25% of $100 = 0.25 x $100 = $25\n",
      "   The discounted price after the first discount is $100 - $25 = $75\n",
      "3. The second discount is 10% off the discounted price.\n",
      "   10% of $75 = 0.10 x $75 = $7.50\n",
      "   The final price after the second discount is $75 - $7.50 = $67.50\n",
      "\n",
      "So, the final price of the shirt is $67.50.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\n",
      "CoT Response: assistant\n",
      "\n",
      "To solve this problem, we need to multiply the speed of the train by the time it travels.\n",
      "\n",
      "Speed = 60 miles per hour\n",
      "Time = 2.5 hours\n",
      "\n",
      "Distance = Speed x Time\n",
      "= 60 miles/hour x 2.5 hours\n",
      "= 150 miles\n",
      "\n",
      "The train will travel 150 miles in 2.5 hours.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?\n",
      "CoT Response: assistant\n",
      "\n",
      "To solve this problem, we can break it down into steps:\n",
      "\n",
      "1. First, we know that 5 machines can make 5 widgets in 5 minutes. This means that each machine can make 1 widget in 5 minutes.\n",
      "2. If we have 100 machines, we can multiply the number of machines by the time it takes for one machine to make one widget. So, we multiply 100 machines by 5 minutes.\n",
      "3. 100 machines * 5 minutes = 500 minutes.\n",
      "\n",
      "Therefore, it would take 100 machines 500 minutes to make 100 widgets.\n",
      "\n",
      "Problem: A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\n",
      "CoT Response: assistant\n",
      "\n",
      "To solve this problem, we can follow these steps:\n",
      "\n",
      "1. Let's represent the cost of the ball as \"x\".\n",
      "2. Since the bat costs $1.00 more than the ball, the cost of the bat can be represented as \"x + $1.00\".\n",
      "3. The total cost of the bat and the ball is given as $1.10. We can write an equation to represent this: x + (x + $1.00) = $1.10.\n",
      "4. Now, we can simplify the equation by combining like terms: 2x + $1.00 = $1.10.\n",
      "5. To isolate x, we need to subtract $1.00 from both sides of the equation: 2x = $1.10 - $1.00.\n",
      "6. Simplifying further, we get: 2x = $0.10.\n",
      "7. To find the value of x, we need to divide both sides by 2: x = $0.10 / 2.\n",
      "8. Therefore, the cost of the ball is $0.05.\n",
      "\n",
      "So, the ball costs $0.05.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cot_prompt(problem):\n",
    "    \"\"\"\n",
    "    Perform Chain-of-Thought prompting for a reasoning problem.\n",
    "\n",
    "    Args:\n",
    "        problem (str): The reasoning problem\n",
    "\n",
    "    Returns:\n",
    "        str: The model's response\n",
    "    \"\"\"\n",
    "    prompt = f\"Answer the following question by thinking step by step: {problem}\"\n",
    "    return query_llm(prompt)\n",
    "\n",
    "# Test CoT prompting on our reasoning problems\n",
    "cot_results = []\n",
    "for problem in reasoning_problems:\n",
    "    response = cot_prompt(problem[0])  # Get the response from the model\n",
    "    cot_results.append({\n",
    "        \"problem\": problem[0],\n",
    "        \"response\": response\n",
    "    })\n",
    "    print(f\"Problem: {problem[0]}\")\n",
    "    print(f\"CoT Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1946788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discounted price, what is the final price of the shirt?\n",
      "Few-shot CoT Response: assistant\n",
      "\n",
      "To find the final price of the shirt, we need to calculate the discount step by step.\n",
      "\n",
      "1. First, calculate the initial discount: 25% of $100 = 0.25 × $100 = $25.\n",
      "   The price after the first discount is $100 - $25 = $75.\n",
      "\n",
      "2. Then, calculate the additional discount: 10% of $75 = 0.10 × $75 = $7.50.\n",
      "   The price after the second discount is $75 - $7.50 = $67.50.\n",
      "\n",
      "So, the final price of the shirt is $67.50.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\n",
      "Few-shot CoT Response: assistant\n",
      "\n",
      "To find the distance the train will travel in 2.5 hours, we need to multiply the speed by the time.\n",
      "\n",
      "Distance = Speed × Time\n",
      "Distance = 60 miles/hour × 2.5 hours\n",
      "Distance = 150 miles\n",
      "\n",
      "So, the train will travel 150 miles in 2.5 hours.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?\n",
      "Few-shot CoT Response: assistant\n",
      "\n",
      "Let's solve the problem step by step.\n",
      "\n",
      "If it takes 5 machines 5 minutes to make 5 widgets, we need to find out how long it takes 100 machines to make 100 widgets.\n",
      "\n",
      "First, let's find out how long it takes 1 machine to make 1 widget. Since 5 machines make 5 widgets in 5 minutes, 1 machine will take 5 times longer to make 1 widget. \n",
      "\n",
      "So, 1 machine takes 5 minutes × 5 = 25 minutes to make 1 widget.\n",
      "\n",
      "Now, if 1 machine takes 25 minutes to make 1 widget, 100 machines will take 25 minutes × 100 = 2500 minutes to make 100 widgets.\n",
      "\n",
      "To convert minutes to hours, we divide by 60 (since there are 60 minutes in an hour). \n",
      "\n",
      "2500 minutes ÷ 60 = 41.67 hours.\n",
      "\n",
      "Therefore, it will take 100 machines 41.67 hours to make 100 widgets.\n",
      "\n",
      "Problem: A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\n",
      "Few-shot CoT Response: assistant\n",
      "\n",
      "Let's solve the last problem step by step.\n",
      "\n",
      "Let the cost of the ball be x dollars. Since the bat costs $1.00 more than the ball, the cost of the bat is x + $1.00.\n",
      "\n",
      "The total cost of the bat and the ball is $1.10, so we can write an equation:\n",
      "\n",
      "x + (x + $1.00) = $1.10\n",
      "\n",
      "Combine like terms:\n",
      "\n",
      "2x + $1.00 = $1.10\n",
      "\n",
      "Subtract $1.00 from both sides:\n",
      "\n",
      "2x = $0.10\n",
      "\n",
      "Divide both sides by 2:\n",
      "\n",
      "x = $0.05\n",
      "\n",
      "So, the ball costs $0.05.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def few_shot_cot_prompt(problem):\n",
    "    \"\"\"\n",
    "    Perform few-shot Chain-of-Thought prompting.\n",
    "\n",
    "    Args:\n",
    "        problem (str): The reasoning problem\n",
    "\n",
    "    Returns:\n",
    "        str: The model's response\n",
    "    \"\"\"\n",
    "    prompt = \"\"\"\n",
    "    I'll solve some math problems step by step.\n",
    "\n",
    "    Problem: If John has 5 apples and gives 2 to Mary, how many apples does John have left?\n",
    "    Solution: John starts with 5 apples. He gives 2 apples to Mary. So, John has 5 - 2 = 3 apples left.\n",
    "\n",
    "    Problem: A rectangle has a length of 10 cm and a width of 5 cm. What is its area?\n",
    "    Solution: The area of a rectangle is calculated by multiplying length × width. So, the area is 10 cm × 5 cm = 50 square cm.\n",
    "\n",
    "    Problem: If a car travels at 60 miles per hour, how far will it travel in 2 hours?\n",
    "    Solution: Distance = Speed × Time. So, the car will travel 60 miles/hour × 2 hours = 120 miles.\n",
    "\n",
    "    Problem: {problem}\n",
    "    Solution:\n",
    "    \"\"\".format(problem=problem)\n",
    "\n",
    "    return query_llm(prompt)\n",
    "\n",
    "# Test few-shot CoT prompting on our reasoning problems\n",
    "few_shot_cot_results = []\n",
    "for problem in reasoning_problems:\n",
    "    response = few_shot_cot_prompt(problem[0])  # Get the response from the model\n",
    "    few_shot_cot_results.append({\n",
    "        \"problem\": problem[0],\n",
    "        \"response\": response\n",
    "    })\n",
    "    print(f\"Problem: {problem[0]}\")\n",
    "    print(f\"Few-shot CoT Response: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f809583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Problem  \\\n",
      "0  [If a shirt originally costs $100 and is on sa...   \n",
      "1  [A train travels at a speed of 60 miles per ho...   \n",
      "2  [If it takes 5 machines 5 minutes to make 5 wi...   \n",
      "3  [A bat and a ball cost $1.10 in total. The bat...   \n",
      "\n",
      "                                     Standard Answer  \\\n",
      "0                                             $67.50   \n",
      "1                                                      \n",
      "2  Let's set up the proportion:\\n\\n5 machines / 5...   \n",
      "3                                              $0.05   \n",
      "\n",
      "                                          CoT Answer  \\\n",
      "0                                             $67.50   \n",
      "1  assistant\\n\\nTo solve this problem, we need to...   \n",
      "2  Therefore, it would take 100 machines 500 minu...   \n",
      "3                                              $0.05   \n",
      "\n",
      "                                 Few-shot CoT Answer  \n",
      "0                                             $67.50  \n",
      "1  5 hours\\nDistance = 150 miles\\n\\nSo, the train...  \n",
      "2            Therefore, it will take 100 machines 41  \n",
      "3                                              $0.05  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_final_answer(response):\n",
    "    \"\"\"\n",
    "    Attempt to extract just the final numerical answer from a response.\n",
    "    This is a simple implementation and may need refinement for complex responses.\n",
    "\n",
    "    Args:\n",
    "        response (str): The model's full response\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted final answer, or the original response if extraction fails\n",
    "    \"\"\"\n",
    "    # Look for common patterns in answers\n",
    "    if \"$\" in response:\n",
    "        # Try to find monetary amounts\n",
    "        matches = re.findall(r'\\$\\d+\\.?\\d*', response)\n",
    "        if matches:\n",
    "            return matches[-1]  # Return the last monetary amount found\n",
    "\n",
    "    # Look for the last sentence that might contain the answer\n",
    "    sentences = response.split('.')\n",
    "    for sentence in reversed(sentences):\n",
    "        if any(word in sentence.lower() for word in ['answer', 'result', 'therefore', 'so', 'thus', 'final']):\n",
    "            return sentence.strip()\n",
    "\n",
    "    # If we can't extract a specific answer, return the last sentence\n",
    "    if sentences:\n",
    "        return sentences[-1].strip()\n",
    "\n",
    "    return response\n",
    "\n",
    "# Compare the approaches\n",
    "comparison_data = []\n",
    "for i in range(len(reasoning_problems)):\n",
    "    standard_answer = extract_final_answer(standard_results[i][\"response\"])\n",
    "    cot_answer = extract_final_answer(cot_results[i][\"response\"])\n",
    "    few_shot_cot_answer = extract_final_answer(few_shot_cot_results[i][\"response\"])\n",
    "\n",
    "    comparison_data.append({\n",
    "        \"Problem\": reasoning_problems[i],\n",
    "        \"Standard Answer\": standard_answer,\n",
    "        \"CoT Answer\": cot_answer,\n",
    "        \"Few-shot CoT Answer\": few_shot_cot_answer\n",
    "    })\n",
    "\n",
    "# Create a DataFrame to show the results\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df)\n",
    "\n",
    "# You can also save this to a CSV for further analysis\n",
    "comparison_df.to_csv(\"cot_comparison.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e0ca0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_problems = [\n",
    "    \"Should a small business invest in expensive automation technology or hire more staff?\",\n",
    "    \"Is it better to pursue higher education immediately after undergraduate studies or gain work experience first?\",\n",
    "    \"For a city with traffic congestion, should they invest in expanding roads or improving public transportation?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b62808a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating initial thoughts for: Should a small business invest in expensive automation technology or hire more staff?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating thoughts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: assistant Here are three different initial thought... Score: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 1. **Cost-Benefit Analysis Approach**: From a pure... Score: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 2. **Operational Efficiency Perspective**: This ap... Score: 8\n",
      "Selected best thought: 2. **Operational Efficiency Perspective**: This approach focuses on the operational efficiency of th...\n",
      "Expanding best thought...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating final answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Answer:\n",
      "assistant\n",
      "\n",
      "Based on the operational efficiency perspective, a small business should consider investing in automation technology if it can:\n",
      "\n",
      "1. Identify areas where automation can streamline processes, reduce waste, and increase productivity.\n",
      "2. Weigh the costs of automation against the benefits, considering the potential return on investment (ROI) and payback period.\n",
      "3. Evaluate the type of automation that best suits the business's needs, such as discrete, discrete-integrated, or hybrid automation.\n",
      "4. Assess how automation can improve productivity and efficiency, while also considering potential challenges and risks.\n",
      "\n",
      "If the business determines that automation is the best option, it should:\n",
      "\n",
      "1. Develop a phased implementation plan to minimize disruption and ensure a smooth transition.\n",
      "2. Establish a project team to oversee the implementation process.\n",
      "3. Continuously evaluate and refine the implementation to ensure it meets the business's goals and objectives.\n",
      "\n",
      "On the other hand, if the business determines that hiring more staff is the best option, it should:\n",
      "\n",
      "1. Evaluate the current staffing levels and roles within the business.\n",
      "2. Identify areas where hiring more staff can improve productivity and efficiency.\n",
      "3. Consider the potential benefits of hiring, such as increased morale and engagement.\n",
      "\n",
      "Ultimately, the decision to invest in automation or hire more staff depends on the specific needs and goals of the business. A thorough analysis and evaluation of the options will help the business make an informed decision.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Generating initial thoughts for: Is it better to pursue higher education immediately after undergraduate studies or gain work experience first?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating thoughts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: assistant Here are three different initial thought... Score: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 1. **The Traditional Path: Emphasizing Immediate H... Score: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 2. **The Practical Approach: Focusing on Work Expe... Score: 30\n",
      "Selected best thought: 1. **The Traditional Path: Emphasizing Immediate Higher Education** Pursuing higher education immedi...\n",
      "Expanding best thought...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating final answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Answer:\n",
      "assistant\n",
      "\n",
      "Based on the step-by-step reasoning process, the final answer is that there is no one-size-fits-all solution. The best approach depends on individual circumstances, goals, and priorities. However, here are some general recommendations:\n",
      "\n",
      "**For those with clear career goals and financial means:**\n",
      "Pursuing higher education immediately after undergraduate studies can be a good option, as it can accelerate career advancement and increase earning potential.\n",
      "\n",
      "**For those with uncertain career goals or financial constraints:**\n",
      "Gaining work experience first can be beneficial, as it provides practical skills, confidence, and networking opportunities. This can also help individuals explore different career paths and gain a better understanding of their strengths and weaknesses.\n",
      "\n",
      "**For those who value work-life balance and flexibility:**\n",
      "Considering alternative paths, such as part-time or online programs, internships, or freelancing, can offer a balance between education and work experience.\n",
      "\n",
      "**Ultimately, the decision should be based on:**\n",
      "\n",
      "1. Personal goals and priorities\n",
      "2. Financial constraints and means\n",
      "3. Career aspirations and interests\n",
      "4. Time management and adaptability\n",
      "5. Ability to balance work and education\n",
      "\n",
      "It's essential to weigh the pros and cons of each option, consider seeking advice, and make a decision that aligns with your values and goals.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Generating initial thoughts for: For a city with traffic congestion, should they invest in expanding roads or improving public transportation?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating thoughts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: assistant Here are three different initial thought... Score: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 1. **Economic Efficiency Perspective**: From an ec... Score: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 2. **Environmental Sustainability Perspective**: F... Score: 7\n",
      "Selected best thought: 2. **Environmental Sustainability Perspective**: From an environmental perspective, the city should ...\n",
      "Expanding best thought...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating final answer...\n",
      "\n",
      "Final Answer:\n",
      "assistant\n",
      "\n",
      "Based on the analysis and evaluation of the environmental sustainability perspective, I recommend that the city invest in improving public transportation, rather than expanding roads. This decision is supported by the potential health and social benefits of alternative modes of transportation, such as reduced rates of obesity and cardiovascular disease, and increased social interaction. Additionally, improving public transportation can lead to reduced traffic congestion, decreased fuel consumption, and increased productivity, as well as improved air quality and greenhouse gas emissions. While expanding roads may provide short-term relief from traffic congestion, the long-term environmental costs and health impacts of increased vehicle usage outweigh the benefits. Furthermore, investing in public transportation can have positive economic benefits, such as reduced healthcare costs and increased economic activity, and can promote a more sustainable and livable city.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_thoughts(problem, n=3):\n",
    "    \"\"\"Generate multiple initial thoughts/angles for a problem.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    For the following problem, generate {n} different initial thoughts or approaches to solve it.\n",
    "    Each thought should represent a different perspective or starting point.\n",
    "    Problem: {problem}\n",
    "    Generate {n} distinct thoughts numbered 1-{n}:\n",
    "    \"\"\"\n",
    "\n",
    "    response = query_llm(prompt, max_new_tokens=1000)\n",
    "\n",
    "    # Parse the response to extract individual thoughts\n",
    "    thoughts = []\n",
    "    current_thought = \"\"\n",
    "\n",
    "    for line in response.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Check if line starts with a number followed by period or colon\n",
    "        if any(line.startswith(f\"{i}.\") for i in range(1, n+1)):\n",
    "            if current_thought:\n",
    "                thoughts.append(current_thought.strip())\n",
    "            current_thought = line\n",
    "        else:\n",
    "            current_thought += \" \" + line\n",
    "\n",
    "    # Add the last thought\n",
    "    if current_thought:\n",
    "        thoughts.append(current_thought.strip())\n",
    "\n",
    "    # Ensure we have exactly n thoughts (or as many as we could parse)\n",
    "    return thoughts[:n]\n",
    "\n",
    "def evaluate_thought(problem, thought):\n",
    "    \"\"\"Evaluate a single thought for its potential in solving the problem.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Problem: {problem}\n",
    "    Thought: {thought}\n",
    "    Evaluate this thought on a scale of 1-10 based on:\n",
    "    1. Relevance to the problem\n",
    "    2. Creativity and uniqueness\n",
    "    3. Potential to lead to a good solution\n",
    "    4. Practical feasibility\n",
    "    Provide a numerical score for each criterion, an overall score, and brief reasoning for your evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    response = query_llm(prompt)\n",
    "\n",
    "    # Extract overall score (this is a simple implementation)\n",
    "    import re\n",
    "    score_match = re.search(r'overall score[:\\s]*(\\d+)', response.lower())\n",
    "\n",
    "    overall_score = 5  # Default middle score\n",
    "    if score_match:\n",
    "        try:\n",
    "            overall_score = int(score_match.group(1))\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    return {\n",
    "        \"thought\": thought,\n",
    "        \"evaluation\": response,\n",
    "        \"score\": overall_score\n",
    "    }\n",
    "\n",
    "def expand_thought(problem, thought):\n",
    "    \"\"\"Expand a thought with a detailed reasoning path.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Problem: {problem}\n",
    "    Thought: {thought}\n",
    "    Expand this thought into a detailed step-by-step reasoning path that addresses the problem.\n",
    "    Consider implications, potential challenges, and possible outcomes.\n",
    "    \"\"\"\n",
    "    return query_llm(prompt, max_new_tokens=1000)\n",
    "\n",
    "def tot_solve(problem):\n",
    "    \"\"\"Solve a problem using Tree of Thoughts approach.\"\"\"\n",
    "    # Step 1: Generate multiple initial thoughts\n",
    "    print(f\"Generating initial thoughts for: {problem}\")\n",
    "    thoughts = generate_thoughts(problem, n=3)\n",
    "\n",
    "    # Step 2: Evaluate each thought\n",
    "    print(\"Evaluating thoughts...\")\n",
    "    evaluations = []\n",
    "    for thought in thoughts:\n",
    "        eval_result = evaluate_thought(problem, thought)\n",
    "        evaluations.append(eval_result)\n",
    "        print(f\"Thought: {thought[:50]}... Score: {eval_result['score']}\")\n",
    "\n",
    "    # Step 3: Select the most promising thought\n",
    "    evaluations.sort(key=lambda x: x['score'], reverse=True)\n",
    "    best_thought = evaluations[0]['thought']\n",
    "    print(f\"Selected best thought: {best_thought[:100]}...\")\n",
    "\n",
    "    # Step 4: Expand the most promising thought\n",
    "    print(\"Expanding best thought...\")\n",
    "    expanded_reasoning = expand_thought(problem, best_thought)\n",
    "\n",
    "    # Step 5: Generate final answer based on expanded reasoning\n",
    "    print(\"Generating final answer...\")\n",
    "    prompt = f\"\"\"\n",
    "    Problem: {problem}\n",
    "    Reasoning process:\n",
    "    {expanded_reasoning}\n",
    "    Based on this reasoning, what is the final answer or recommendation for this problem?\n",
    "    Provide a concise but comprehensive answer.\n",
    "    \"\"\"\n",
    "\n",
    "    final_answer = query_llm(prompt)\n",
    "\n",
    "    return {\n",
    "        \"problem\": problem,\n",
    "        \"initial_thoughts\": thoughts,\n",
    "        \"evaluations\": evaluations,\n",
    "        \"best_thought\": best_thought,\n",
    "        \"expanded_reasoning\": expanded_reasoning,\n",
    "        \"final_answer\": final_answer\n",
    "    }\n",
    "\n",
    "# Test ToT on our decision problems\n",
    "decision_problems = [\n",
    "    \"Should a small business invest in expensive automation technology or hire more staff?\",\n",
    "    \"Is it better to pursue higher education immediately after undergraduate studies or gain work experience first?\",\n",
    "    \"For a city with traffic congestion, should they invest in expanding roads or improving public transportation?\"\n",
    "]\n",
    "\n",
    "tot_results = []\n",
    "for problem in decision_problems:\n",
    "    result = tot_solve(problem)\n",
    "    tot_results.append(result)\n",
    "    print(\"\\nFinal Answer:\")\n",
    "    print(result[\"final_answer\"])\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c07788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: Should a small business invest in expensive automation technology or hire more staff?\n",
      "\n",
      "Initial Thoughts:\n",
      "1. assistant Here are three different initial thoughts or approaches to solve the problem: (Score: 7)\n",
      "\n",
      "2. 1. **Cost-Benefit Analysis Approach**: From a purely financial perspective, a small business should consider the cost of implementing expensive automation technology versus the cost of hiring more staff. This approach involves weighing the upfront costs of the technology against the potential long-term savings and increased efficiency it can bring. A business can calculate the cost of ownership, maintenance, and potential returns on investment (ROI) to make a data-driven decision. This approach helps businesses prioritize their spending based on financial metrics. (Score: 7)\n",
      "\n",
      "3. 2. **Operational Efficiency Perspective**: This approach focuses on the operational efficiency of the business. A small business should consider how automation can streamline processes, reduce waste, and increase productivity. By identifying bottlenecks and areas where automation can make a significant impact, a business can optimize its operations and free up resources for more strategic initiatives. This approach prioritizes the business's ability to deliver high-quality products or services while maintaining competitiveness. (Score: 8)\n",
      "\n",
      "Best Thought Selected: 2. **Operational Efficiency Perspective**: This approach focuses on the operational efficiency of the business. A small business should consider how automation can streamline processes, reduce waste, and increase productivity. By identifying bottlenecks and areas where automation can make a significant impact, a business can optimize its operations and free up resources for more strategic initiatives. This approach prioritizes the business's ability to deliver high-quality products or services while maintaining competitiveness.\n",
      "\n",
      "Final Answer: assistant\n",
      "\n",
      "Based on the operational efficiency perspective, a small business should consider investing in automation technology if it can:\n",
      "\n",
      "1. Identify areas where automation can streamline processes, reduce waste, and increase productivity.\n",
      "2. Weigh the costs of automation against the benefits, considering the potential return on investment (ROI) and payback period.\n",
      "3. Evaluate the type of automation that best suits the business's needs, such as discrete, discrete-integrated, or hybrid automation.\n",
      "4. Assess how automation can improve productivity and efficiency, while also considering potential challenges and risks.\n",
      "\n",
      "If the business determines that automation is the best option, it should:\n",
      "\n",
      "1. Develop a phased implementation plan to minimize disruption and ensure a smooth transition.\n",
      "2. Establish a project team to oversee the implementation process.\n",
      "3. Continuously evaluate and refine the implementation to ensure it meets the business's goals and objectives.\n",
      "\n",
      "On the other hand, if the business determines that hiring more staff is the best option, it should:\n",
      "\n",
      "1. Evaluate the current staffing levels and roles within the business.\n",
      "2. Identify areas where hiring more staff can improve productivity and efficiency.\n",
      "3. Consider the potential benefits of hiring, such as increased morale and engagement.\n",
      "\n",
      "Ultimately, the decision to invest in automation or hire more staff depends on the specific needs and goals of the business. A thorough analysis and evaluation of the options will help the business make an informed decision.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Problem: Is it better to pursue higher education immediately after undergraduate studies or gain work experience first?\n",
      "\n",
      "Initial Thoughts:\n",
      "1. assistant Here are three different initial thoughts or approaches to solve the problem: (Score: 28)\n",
      "\n",
      "2. 1. **The Traditional Path: Emphasizing Immediate Higher Education** Pursuing higher education immediately after undergraduate studies is often seen as the traditional path to securing a stable and well-paying job. This approach assumes that the individual is well-prepared to take on the academic rigor and demands of a graduate program, and that the potential benefits of a higher degree outweigh the costs of delayed entry into the workforce. By enrolling in a graduate program shortly after undergraduate studies, individuals can: * Leverage their existing knowledge and experience to accelerate their career advancement * Gain specialized skills and expertise in their chosen field * Increase their earning potential and job prospects However, this approach may not be suitable for everyone, particularly those who need to gain practical experience or build their confidence in their chosen field before pursuing advanced studies. (Score: 30)\n",
      "\n",
      "3. 2. **The Practical Approach: Focusing on Work Experience and Skill-Building** Gaining work experience before pursuing higher education can be a more practical and effective approach. This perspective emphasizes the importance of building a strong foundation of skills, knowledge, and experience in the workplace before investing in advanced education. By doing so, individuals can: * Develop a clearer understanding of their strengths and weaknesses * Gain practical experience and a deeper understanding of the industry or field * Build a professional network and establish themselves as experts in their chosen field * Avoid the financial burden of pursuing higher education immediately However, this approach may require individuals to take on more responsibilities, work longer hours, and potentially sacrifice some personal time and energy. (Score: 30)\n",
      "\n",
      "Best Thought Selected: 1. **The Traditional Path: Emphasizing Immediate Higher Education** Pursuing higher education immediately after undergraduate studies is often seen as the traditional path to securing a stable and well-paying job. This approach assumes that the individual is well-prepared to take on the academic rigor and demands of a graduate program, and that the potential benefits of a higher degree outweigh the costs of delayed entry into the workforce. By enrolling in a graduate program shortly after undergraduate studies, individuals can: * Leverage their existing knowledge and experience to accelerate their career advancement * Gain specialized skills and expertise in their chosen field * Increase their earning potential and job prospects However, this approach may not be suitable for everyone, particularly those who need to gain practical experience or build their confidence in their chosen field before pursuing advanced studies.\n",
      "\n",
      "Final Answer: assistant\n",
      "\n",
      "Based on the step-by-step reasoning process, the final answer is that there is no one-size-fits-all solution. The best approach depends on individual circumstances, goals, and priorities. However, here are some general recommendations:\n",
      "\n",
      "**For those with clear career goals and financial means:**\n",
      "Pursuing higher education immediately after undergraduate studies can be a good option, as it can accelerate career advancement and increase earning potential.\n",
      "\n",
      "**For those with uncertain career goals or financial constraints:**\n",
      "Gaining work experience first can be beneficial, as it provides practical skills, confidence, and networking opportunities. This can also help individuals explore different career paths and gain a better understanding of their strengths and weaknesses.\n",
      "\n",
      "**For those who value work-life balance and flexibility:**\n",
      "Considering alternative paths, such as part-time or online programs, internships, or freelancing, can offer a balance between education and work experience.\n",
      "\n",
      "**Ultimately, the decision should be based on:**\n",
      "\n",
      "1. Personal goals and priorities\n",
      "2. Financial constraints and means\n",
      "3. Career aspirations and interests\n",
      "4. Time management and adaptability\n",
      "5. Ability to balance work and education\n",
      "\n",
      "It's essential to weigh the pros and cons of each option, consider seeking advice, and make a decision that aligns with your values and goals.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Problem: For a city with traffic congestion, should they invest in expanding roads or improving public transportation?\n",
      "\n",
      "Initial Thoughts:\n",
      "1. assistant Here are three different initial thoughts or approaches to solve the problem of traffic congestion in a city, each representing a distinct perspective or starting point: (Score: 5)\n",
      "\n",
      "2. 1. **Economic Efficiency Perspective**: From an economic standpoint, the city should prioritize investing in expanding roads. This approach focuses on reducing travel times and increasing the overall efficiency of the transportation system. By expanding roads, the city can reduce congestion, decrease travel times, and increase productivity. This, in turn, can lead to increased economic growth, as businesses and individuals can move goods and people more quickly and efficiently. This approach also assumes that the city's infrastructure can be expanded to accommodate increased traffic, without overburdening the existing infrastructure. (Score: 6)\n",
      "\n",
      "3. 2. **Environmental Sustainability Perspective**: From an environmental perspective, the city should prioritize improving public transportation. This approach focuses on reducing the city's carbon footprint and promoting sustainable transportation options. By investing in public transportation, the city can decrease air pollution, reduce greenhouse gas emissions, and promote a more environmentally friendly transportation system. This approach also encourages the use of alternative modes of transportation, such as walking, cycling, and electric vehicles, which can have numerous health and social benefits. Additionally, public transportation can be designed to be more efficient and sustainable, reducing the need for personal vehicles. (Score: 7)\n",
      "\n",
      "Best Thought Selected: 2. **Environmental Sustainability Perspective**: From an environmental perspective, the city should prioritize improving public transportation. This approach focuses on reducing the city's carbon footprint and promoting sustainable transportation options. By investing in public transportation, the city can decrease air pollution, reduce greenhouse gas emissions, and promote a more environmentally friendly transportation system. This approach also encourages the use of alternative modes of transportation, such as walking, cycling, and electric vehicles, which can have numerous health and social benefits. Additionally, public transportation can be designed to be more efficient and sustainable, reducing the need for personal vehicles.\n",
      "\n",
      "Final Answer: assistant\n",
      "\n",
      "Based on the analysis and evaluation of the environmental sustainability perspective, I recommend that the city invest in improving public transportation, rather than expanding roads. This decision is supported by the potential health and social benefits of alternative modes of transportation, such as reduced rates of obesity and cardiovascular disease, and increased social interaction. Additionally, improving public transportation can lead to reduced traffic congestion, decreased fuel consumption, and increased productivity, as well as improved air quality and greenhouse gas emissions. While expanding roads may provide short-term relief from traffic congestion, the long-term environmental costs and health impacts of increased vehicle usage outweigh the benefits. Furthermore, investing in public transportation can have positive economic benefits, such as reduced healthcare costs and increased economic activity, and can promote a more sustainable and livable city.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_tot_summary(tot_result):\n",
    "    \"\"\"\n",
    "    Create a summary of the Tree of Thoughts process for a problem.\n",
    "\n",
    "    Args:\n",
    "        tot_result (dict): Result from tot_solve\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted summary\n",
    "    \"\"\"\n",
    "    problem = tot_result[\"problem\"]\n",
    "    thoughts = tot_result[\"initial_thoughts\"]\n",
    "    evaluations = tot_result[\"evaluations\"]\n",
    "    best_thought = tot_result[\"best_thought\"]\n",
    "    final_answer = tot_result[\"final_answer\"]\n",
    "\n",
    "    summary = f\"Problem: {problem}\\n\\n\"\n",
    "    summary += \"Initial Thoughts:\\n\"\n",
    "\n",
    "    for i, thought in enumerate(thoughts):\n",
    "        # Find the evaluation for this thought\n",
    "        eval_score = \"N/A\"\n",
    "        for eval_result in evaluations:\n",
    "            if eval_result[\"thought\"] == thought:\n",
    "                eval_score = eval_result[\"score\"]\n",
    "                break\n",
    "\n",
    "        summary += f\"{i+1}. {thought} (Score: {eval_score})\\n\\n\"\n",
    "\n",
    "    summary += f\"Best Thought Selected: {best_thought}\\n\\n\"\n",
    "    summary += f\"Final Answer: {final_answer}\\n\"\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Create and display summaries for each problem\n",
    "for result in tot_results:\n",
    "    summary = create_tot_summary(result)\n",
    "    print(summary)\n",
    "    print(\"=\" * 80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5d55575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTechnique:\n",
    "    \"\"\"Base class for prompt techniques.\"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def generate_prompt(self, task):\n",
    "        \"\"\"Generate a prompt for the given task.\"\"\"\n",
    "        return task\n",
    "\n",
    "    def execute(self, task):\n",
    "        \"\"\"Execute the technique on a task and return the response.\"\"\"\n",
    "        prompt = self.generate_prompt(task)\n",
    "        return query_llm(prompt)\n",
    "\n",
    "\n",
    "class StandardPrompt(PromptTechnique):\n",
    "    \"\"\"Standard prompting without any special technique.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Standard\")\n",
    "\n",
    "\n",
    "class ZeroShotPrompt(PromptTechnique):\n",
    "    \"\"\"Zero-shot prompting with clear instructions.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Zero-shot\")\n",
    "\n",
    "    def generate_prompt(self, task):\n",
    "        return f\"Please respond to the following task: {task}\"\n",
    "\n",
    "\n",
    "class FewShotPrompt(PromptTechnique):\n",
    "    \"\"\"Few-shot prompting with examples.\"\"\"\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        super().__init__(\"Few-shot\")\n",
    "        self.examples = examples\n",
    "\n",
    "    def generate_prompt(self, task):\n",
    "        prompt = \"Here are some examples:\\n\\n\"\n",
    "\n",
    "        for example in self.examples:\n",
    "            prompt += f\"Input: {example['input']}\\nOutput: {example['output']}\\n\\n\"\n",
    "\n",
    "        prompt += f\"Input: {task}\\nOutput:\"\n",
    "        return prompt\n",
    "\n",
    "\n",
    "class CoTPrompt(PromptTechnique):\n",
    "    \"\"\"Chain-of-Thought prompting.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Chain-of-Thought\")\n",
    "\n",
    "    def generate_prompt(self, task):\n",
    "        return f\"Think through this step by step: {task}\"\n",
    "\n",
    "\n",
    "class FewShotCoTPrompt(PromptTechnique):\n",
    "    \"\"\"Few-shot Chain-of-Thought prompting.\"\"\"\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        super().__init__(\"Few-shot CoT\")\n",
    "        self.examples = examples\n",
    "\n",
    "    def generate_prompt(self, task):\n",
    "        prompt = \"I'll solve some problems step by step.\\n\\n\"\n",
    "\n",
    "        for example in self.examples:\n",
    "            prompt += f\"Problem: {example['input']}\\nSolution: {example['reasoning']}\\n\\n\"\n",
    "\n",
    "        prompt += f\"Problem: {task}\\nSolution:\"\n",
    "        return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c60d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTechnique:\n",
    "    \"\"\"Base class for prompt techniques.\"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def generate_prompt(self, task):\n",
    "        \"\"\"Generate a prompt for the given task.\"\"\"\n",
    "        return task\n",
    "\n",
    "    def execute(self, task):\n",
    "        \"\"\"Execute the technique on a task and return the response.\"\"\"\n",
    "        prompt = self.generate_prompt(task)\n",
    "        return query_llm(prompt)\n",
    "\n",
    "\n",
    "class StandardPrompt(PromptTechnique):\n",
    "    \"\"\"Standard prompting without any special technique.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Standard\")\n",
    "\n",
    "\n",
    "class ZeroShotPrompt(PromptTechnique):\n",
    "    \"\"\"Zero-shot prompting with clear instructions.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Zero-shot\")\n",
    "\n",
    "    def generate_prompt(self, task):\n",
    "        return f\"Please respond to the following task: {task}\"\n",
    "\n",
    "\n",
    "class FewShotPrompt(PromptTechnique):\n",
    "    \"\"\"Few-shot prompting with examples.\"\"\"\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        super().__init__(\"Few-shot\")\n",
    "        self.examples = examples\n",
    "\n",
    "    def generate_prompt(self, task):\n",
    "        prompt = \"Here are some examples:\\n\\n\"\n",
    "\n",
    "        for example in self.examples:\n",
    "            prompt += f\"Input: {example['input']}\\nOutput: {example['output']}\\n\\n\"\n",
    "\n",
    "        prompt += f\"Input: {task}\\nOutput:\"\n",
    "        return prompt\n",
    "\n",
    "\n",
    "class CoTPrompt(PromptTechnique):\n",
    "    \"\"\"Chain-of-Thought prompting.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Chain-of-Thought\")\n",
    "\n",
    "    def generate_prompt(self, task):\n",
    "        return f\"Think through this step by step: {task}\"\n",
    "\n",
    "\n",
    "class FewShotCoTPrompt(PromptTechnique):\n",
    "    \"\"\"Few-shot Chain-of-Thought prompting.\"\"\"\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        super().__init__(\"Few-shot CoT\")\n",
    "        self.examples = examples\n",
    "\n",
    "    def generate_prompt(self, task):\n",
    "        prompt = \"I'll solve some problems step by step.\\n\\n\"\n",
    "\n",
    "        for example in self.examples:\n",
    "            prompt += f\"Problem: {example['input']}\\nSolution: {example['reasoning']}\\n\\n\"\n",
    "\n",
    "        prompt += f\"Problem: {task}\\nSolution:\"\n",
    "        return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a57dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation tasks by category\n",
    "evaluation_tasks = {\n",
    "    \"math_reasoning\": [\n",
    "        \"If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discounted price, what is the final price?\",\n",
    "        \"A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\"\n",
    "    ],\n",
    "    \"common_sense\": [\n",
    "        \"If I put a few ice cubes in a glass of water at room temperature and leave it for 30 minutes, what will happen?\",\n",
    "        \"Why do cars have seat belts?\"\n",
    "    ],\n",
    "    \"creative_writing\": [\n",
    "        \"Write a short story about a robot that develops emotions.\",\n",
    "        \"Create a poem about autumn leaves.\"\n",
    "    ],\n",
    "    \"classification\": [\n",
    "        \"Classify this review as positive or negative: 'The food was delicious but the service was terrible.'\",\n",
    "        \"Determine if this statement is objective or subjective: 'The movie was released in 2022.'\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Define examples for few-shot techniques\n",
    "few_shot_examples = {\n",
    "    \"math_reasoning\": [\n",
    "        {\n",
    "            \"input\": \"If John has 5 apples and gives 2 to Mary, how many does he have left?\",\n",
    "            \"output\": \"3 apples\",\n",
    "            \"reasoning\": \"John starts with 5 apples. He gives 2 apples to Mary. So, John has 5 - 2 = 3 apples left.\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"A rectangle has a length of 10 cm and a width of 5 cm. What is its area?\",\n",
    "            \"output\": \"50 square cm\",\n",
    "            \"reasoning\": \"The area of a rectangle is calculated by multiplying length × width. So, the area is 10 cm × 5 cm = 50 square cm.\"\n",
    "        }\n",
    "    ],\n",
    "    \"common_sense\": [\n",
    "        {\n",
    "            \"input\": \"What happens if you drop a glass on a hard floor?\",\n",
    "            \"output\": \"The glass will likely break.\",\n",
    "            \"reasoning\": \"Glass is a brittle material. When dropped on a hard floor, the impact force exceeds the material's resistance to breakage.\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Why do plants need sunlight?\",\n",
    "            \"output\": \"Plants need sunlight for photosynthesis.\",\n",
    "            \"reasoning\": \"Plants use sunlight in the process of photosynthesis to convert light energy into chemical energy.\"\n",
    "        }\n",
    "    ],\n",
    "    \"creative_writing\": [\n",
    "        {\n",
    "            \"input\": \"Write a short story about a lost dog.\",\n",
    "            \"output\": \"Max wagged his tail as he chased the squirrel into the woods. Only when it disappeared up a tree did he realize he was lost...\",\n",
    "            \"reasoning\": \"This is a short emotional story with a beginning (dog gets lost), middle (dog searches for a way out), and an ending (dog finds his way home).\"\n",
    "        }\n",
    "    ],\n",
    "    \"classification\": [\n",
    "        {\n",
    "            \"input\": \"Classify this review as positive or negative: 'The movie was fantastic and I enjoyed every minute of it.'\",\n",
    "            \"output\": \"Positive\",\n",
    "            \"reasoning\": \"This review contains positive words like 'fantastic' and states that the reviewer 'enjoyed every minute of it.'\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Classify this review as positive or negative: 'The hotel room was dirty and the staff was rude.'\",\n",
    "            \"output\": \"Negative\",\n",
    "            \"reasoning\": \"This review contains negative descriptions: 'dirty' room and 'rude' staff.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "def evaluate_responses(task_category, responses, ground_truth=None):\n",
    "    \"\"\"Evaluate responses for a given task category.\"\"\"\n",
    "    task_examples = few_shot_examples.get(task_category, [])\n",
    "    evaluation_results = []\n",
    "\n",
    "    for response, example in zip(responses, task_examples):\n",
    "        result = {\n",
    "            \"input\": example[\"input\"],\n",
    "            \"expected_output\": example[\"output\"],\n",
    "            \"response\": response,\n",
    "            \"match\": response == example[\"output\"]\n",
    "        }\n",
    "\n",
    "        if ground_truth:\n",
    "            result[\"ground_truth\"] = ground_truth.get(task_category, {}).get(example[\"input\"], None)\n",
    "\n",
    "        evaluation_results.append(result)\n",
    "\n",
    "    return evaluation_results\n",
    "def evaluate_responses(task_category, responses, ground_truth=None):\n",
    "    \"\"\"Evaluate responses for a given task category.\n",
    "\n",
    "    Args:\n",
    "        task_category (str): Category of the task\n",
    "        responses (dict): Dictionary of technique name to response\n",
    "        ground_truth (list, optional): List of correct answers if available\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    # Define category-specific metrics\n",
    "    metrics = {\n",
    "        \"response_length\": {name: len(response.split()) for name, response in responses.items()}\n",
    "    }\n",
    "\n",
    "    # For math reasoning, we could try to extract numerical answers\n",
    "    if task_category == \"math_reasoning\":\n",
    "        import re\n",
    "\n",
    "        def extract_number(text):\n",
    "            # Try to find numerical answers with optional dollar signs\n",
    "            matches = re.findall(r'(\\$?\\d+\\.?\\d*)', text)\n",
    "            if matches:\n",
    "                return matches[-1]  # Return the last number found\n",
    "            return None\n",
    "\n",
    "        numeric_answers = {name: extract_number(response) for name, response in responses.items()}\n",
    "        metrics[\"extracted_answers\"] = numeric_answers\n",
    "\n",
    "    # Ask LLM to evaluate response quality\n",
    "    prompt = f\"\"\"\n",
    "    Evaluate the quality of the following responses to this task:\n",
    "    Task: {responses['task']}\n",
    "    \"\"\"\n",
    "\n",
    "    for name, response in responses.items():\n",
    "        if name != 'task':\n",
    "            prompt += f\"\\nResponse from {name} technique:\\n{response}\\n\"\n",
    "\n",
    "    prompt += \"\"\"\n",
    "    Please rate each response on a scale of 1-10 for the following criteria:\n",
    "    1. Correctness/Accuracy\n",
    "    2. Clarity and coherence\n",
    "    3. Completeness\n",
    "    4. Relevance to the task\n",
    "    Provide numerical ratings and brief explanations for each technique.\n",
    "    \"\"\"\n",
    "\n",
    "    evaluation = query_llm(prompt, max_new_tokens=1000)\n",
    "    metrics[\"llm_evaluation\"] = evaluation\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "467dfde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating task: If a shirt originally costs $100 and is on sale fo...\n",
      "  Running Standard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running Zero-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running Chain-of-Thought...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running Few-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running Few-shot CoT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating task: A train travels at a speed of 60 miles per hour. H...\n",
      "  Running Standard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running Zero-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running Chain-of-Thought...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running Few-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running Few-shot CoT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task: If a shirt originally costs $100 and is on sale for 25% off, and then an additional 10% is taken off the discounted price, what is the final price?\n",
      "\n",
      "LLM Evaluation:\n",
      "assistant\n",
      "\n",
      "Here are the ratings for each response:\n",
      "\n",
      "**Standard Technique**\n",
      "\n",
      "* Correctness/Accuracy: 9 (The response follows a straightforward and correct mathematical process to find the final price.)\n",
      "* Clarity and coherence: 8 (The response is clear and easy to follow, but may not be explicitly stated that it's a step-by-step process.)\n",
      "* Completeness: 9 (The response includes all necessary calculations to find the final price.)\n",
      "* Relevance to the task: 10 (The response directly addresses the problem and provides a clear solution.)\n",
      "\n",
      "**Zero-shot technique**\n",
      "\n",
      "* Correctness/Accuracy: 9 (The response correctly calculates the final price using the same mathematical process as the standard technique.)\n",
      "* Clarity and coherence: 7 (The response is concise but may not provide explicit explanations or steps, making it slightly less clear than the standard technique.)\n",
      "* Completeness: 8 (The response still includes all necessary calculations to find the final price, but may not be as detailed as the standard technique.)\n",
      "* Relevance to the task: 9 (The response directly addresses the problem and provides a clear solution.)\n",
      "\n",
      "**Chain-of-Thought technique**\n",
      "\n",
      "* Correctness/Accuracy: 9 (The response follows the same mathematical process as the standard technique and provides a clear step-by-step solution.)\n",
      "* Clarity and coherence: 9 (The response provides explicit explanations and steps, making it clear and easy to follow.)\n",
      "* Completeness: 9 (The response includes all necessary calculations to find the final price.)\n",
      "* Relevance to the task: 10 (The response directly addresses the problem and provides a clear solution.)\n",
      "\n",
      "**Few-shot technique**\n",
      "\n",
      "* Correctness/Accuracy: 9 (The response correctly calculates the final price using the same mathematical process as the standard technique.)\n",
      "* Clarity and coherence: 8 (The response is concise but may not provide explicit explanations or steps, making it slightly less clear than the standard technique.)\n",
      "* Completeness: 8 (The response still includes all necessary calculations to find the final price, but may not be as detailed as the standard technique.)\n",
      "* Relevance to the task: 9 (The response directly addresses the problem and provides a clear solution.)\n",
      "\n",
      "**Few-shot CoT technique**\n",
      "\n",
      "* Correctness/Accuracy: 9 (The response follows the same mathematical process as the standard technique and provides a clear step-by-step solution.)\n",
      "* Clarity and coherence: 9 (The response provides explicit explanations and steps, making it clear and easy to follow.)\n",
      "* Completeness: 9 (The response includes all necessary calculations to find the final price.)\n",
      "* Relevance to the task: 10 (The response directly addresses the problem and provides a clear solution.)\n",
      "\n",
      "Overall, the standard technique and the Few-shot CoT technique are the most accurate and clear, with the Chain-of-Thought technique closely following. The Zero-shot technique is also accurate but may be slightly less clear. The Few-shot technique is concise but may be slightly less clear.\n",
      "\n",
      "Response Lengths:\n",
      "  task: 29 words\n",
      "  Standard: 62 words\n",
      "  Zero-shot: 93 words\n",
      "  Chain-of-Thought: 73 words\n",
      "  Few-shot: 69 words\n",
      "  Few-shot CoT: 124 words\n",
      "\n",
      "Task: A train travels at a speed of 60 miles per hour. How far will it travel in 2.5 hours?\n",
      "\n",
      "LLM Evaluation:\n",
      "assistant\n",
      "\n",
      "Here are the ratings for each response technique:\n",
      "\n",
      "**Standard technique:**\n",
      "- Correctness/Accuracy: 10/10\n",
      "- Clarity and coherence: 9/10 (clear and concise language, but lacks elaboration)\n",
      "- Completeness: 8/10 (lacks elaboration on the formula, but still provides the correct answer)\n",
      "- Relevance to the task: 10/10 (directly addresses the task)\n",
      "\n",
      "**Zero-shot technique:**\n",
      "- Correctness/Accuracy: 10/10\n",
      "- Clarity and coherence: 7/10 (lacks explanation of the formula, makes the response feel a bit abrupt)\n",
      "- Completeness: 6/10 (no explanation of the formula or steps involved)\n",
      "- Relevance to the task: 10/10 (directly addresses the task, but lacks elaboration)\n",
      "\n",
      "**Chain-of-Thought technique:**\n",
      "- Correctness/Accuracy: 10/10\n",
      "- Clarity and coherence: 9/10 (clear and step-by-step explanation)\n",
      "- Completeness: 9/10 (explains the process and formula, but might be slightly longer than necessary)\n",
      "- Relevance to the task: 10/10 (directly addresses the task and explains the reasoning)\n",
      "\n",
      "**Few-shot technique:**\n",
      "- Correctness/Accuracy: 10/10\n",
      "- Clarity and coherence: 8/10 (provides a clear explanation of the process, but lacks specific details)\n",
      "- Completeness: 8/10 (explains the process, but might not be as detailed as the Chain-of-Thought technique)\n",
      "- Relevance to the task: 10/10 (directly addresses the task)\n",
      "\n",
      "**Few-shot CoT technique:**\n",
      "- Correctness/Accuracy: 10/10\n",
      "- Clarity and coherence: 9/10 (clear and step-by-step explanation, similar to the Chain-of-Thought technique)\n",
      "- Completeness: 9/10 (explains the process and formula in detail)\n",
      "- Relevance to the task: 10/10 (directly addresses the task and explains the reasoning)\n",
      "\n",
      "Overall, the Standard technique and the Zero-shot technique both provide accurate answers, but the Chain-of-Thought technique and the Few-shot CoT technique provide more detailed explanations, which can make the responses more informative and helpful for users.\n",
      "\n",
      "Response Lengths:\n",
      "  task: 19 words\n",
      "  Standard: 45 words\n",
      "  Zero-shot: 51 words\n",
      "  Chain-of-Thought: 51 words\n",
      "  Few-shot: 41 words\n",
      "  Few-shot CoT: 107 words\n"
     ]
    }
   ],
   "source": [
    "def run_evaluation(task_category, techniques):\n",
    "    \"\"\"Run evaluation for a specific task category using multiple techniques.\n",
    "\n",
    "    Args:\n",
    "        task_category (str): Category of tasks to evaluate\n",
    "        techniques (list): List of PromptTechnique instances\n",
    "\n",
    "    Returns:\n",
    "        list: Evaluation results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for task in evaluation_tasks[task_category]:\n",
    "        print(f\"\\nEvaluating task: {task[:50]}...\")\n",
    "\n",
    "        # Get responses from all techniques\n",
    "        task_responses = {\"task\": task}\n",
    "        for technique in techniques:\n",
    "            print(f\"  Running {technique.name}...\")\n",
    "            response = technique.execute(task)\n",
    "            task_responses[technique.name] = response\n",
    "\n",
    "        # Evaluate the responses\n",
    "        metrics = evaluate_responses(task_category, task_responses)\n",
    "\n",
    "        results.append({\n",
    "            \"task\": task,\n",
    "            \"responses\": task_responses,\n",
    "            \"metrics\": metrics\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Set up techniques for evaluation\n",
    "standard = StandardPrompt()\n",
    "zero_shot = ZeroShotPrompt()\n",
    "cot = CoTPrompt()\n",
    "category = \"math_reasoning\"\n",
    "few_shot = FewShotPrompt(few_shot_examples[category])\n",
    "few_shot_cot = FewShotCoTPrompt(few_shot_examples[category])\n",
    "\n",
    "# Evaluate a specific category\n",
    "category = \"math_reasoning\"\n",
    "techniques = [standard, zero_shot, cot, few_shot, few_shot_cot]\n",
    "evaluation_results = run_evaluation(category, techniques)\n",
    "\n",
    "# Display results\n",
    "for result in evaluation_results:\n",
    "    print(f\"\\nTask: {result['task']}\")\n",
    "    print(\"\\nLLM Evaluation:\")\n",
    "    print(result['metrics']['llm_evaluation'])\n",
    "\n",
    "    print(\"\\nResponse Lengths:\")\n",
    "    for technique, length in result['metrics']['response_length'].items():\n",
    "        print(f\"  {technique}: {length} words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18d7aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_scores_from_evaluation(evaluation_text):\n",
    "    \"\"\"\n",
    "    Extract numerical scores from LLM evaluation text.\n",
    "\n",
    "    Args:\n",
    "        evaluation_text (str): Text containing evaluations\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of technique to scores\n",
    "    \"\"\"\n",
    "    technique_names = [\"Standard\", \"Zero-shot\", \"Chain-of-Thought\", \"Few-shot\", \"Few-shot CoT\"]\n",
    "    criteria = [\"Correctness\", \"Clarity\", \"Completeness\", \"Relevance\"]\n",
    "    scores = {technique: {} for technique in technique_names}\n",
    "\n",
    "    for technique in technique_names:\n",
    "        pattern = fr'{technique}[^0-9]*(\\d+)(?:/10)?'\n",
    "        matches = re.findall(pattern, evaluation_text)\n",
    "\n",
    "        if matches:\n",
    "            for i, score in enumerate(matches[:len(criteria)]):\n",
    "                try:\n",
    "                    scores[technique][criteria[i]] = int(score)\n",
    "                except ValueError:\n",
    "                    scores[technique][criteria[i]] = 0\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1254bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_evaluation_results(evaluation_results):\n",
    "    \"\"\"\n",
    "    Plot evaluation results for visual comparison.\n",
    "\n",
    "    Args:\n",
    "        evaluation_results (list): Results from run_evaluation\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    all_scores = []\n",
    "    technique_names = []\n",
    "\n",
    "    for result in evaluation_results:\n",
    "        llm_eval = result['metrics']['llm_evaluation']\n",
    "        scores = extract_scores_from_evaluation(llm_eval)\n",
    "        all_scores.append(scores)\n",
    "\n",
    "        if not technique_names and scores:\n",
    "            technique_names = list(scores.keys())\n",
    "\n",
    "    # Initialize aggregation\n",
    "    criteria = [\"Correctness\", \"Clarity\", \"Completeness\", \"Relevance\"]\n",
    "    agg_scores = {\n",
    "        technique: {criterion: [] for criterion in criteria}\n",
    "        for technique in technique_names\n",
    "    }\n",
    "\n",
    "    for scores in all_scores:\n",
    "        for technique in technique_names:\n",
    "            if technique in scores:\n",
    "                for criterion, score in scores[technique].items():\n",
    "                    agg_scores[technique][criterion].append(score)\n",
    "\n",
    "    # Compute averages\n",
    "    avg_scores = {\n",
    "        technique: {\n",
    "            criterion: np.mean(scores) if scores else 0\n",
    "            for criterion, scores in criteria_scores.items()\n",
    "        }\n",
    "        for technique, criteria_scores in agg_scores.items()\n",
    "    }\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    x = np.arange(len(criteria))\n",
    "    width = 0.15\n",
    "    multiplier = 0\n",
    "\n",
    "    for technique, scores in avg_scores.items():\n",
    "        offset = width * multiplier\n",
    "        values = [scores.get(criterion, 0) for criterion in criteria]\n",
    "        ax.bar(x + offset, values, width, label=technique)\n",
    "        multiplier += 1\n",
    "\n",
    "    ax.set_xlabel('Criteria')\n",
    "    ax.set_ylabel('Average Score (1-10)')\n",
    "    ax.set_title('Comparison of Prompting Techniques')\n",
    "    ax.set_xticks(x + width * (len(avg_scores) - 1) / 2)\n",
    "    ax.set_xticklabels(criteria)\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_ylim(0, 10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cae6ec58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Suppose `evaluation_results` is a list of results with the key structure:\n",
    "# {'metrics': {'llm_evaluation': \"Standard: 8/10, Clarity: 7/10, ...\" }}\n",
    "\n",
    "plot_evaluation_results(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59b16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
